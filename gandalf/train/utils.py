import numpy as np
import os
import tensorflow as tf
import glob

def load_data(id_, data_path='results/data', include_training=False, base_dir=None):
    '''Load test data into a dictionary. The dictionary contains the following entries:
        X: data to disentangle
        params: original parameters
        cond_params: conditional parameters (a normalized subset of the original parameters)
        params_names: parameter names
        cond_params_names: conditional parameters names
        ids: data identifiers
        axis_labels: data axis labels
        z: latent space generated by autoencoder
        decoded: autoencoder predictions (decoded data)
    
    Parameters
    ----------
    id_ : str
        Identifier from which the trained model and the data corresponding to it are obtained.
    data_path: str, default 'results/data'
        Path of the folder where the data is stored
    include_training: bool, default False
        Also load training data (if saved)
        
    '''
    base_dir = os.path.dirname(__file__) if base_dir is None else base_dir
    _X = np.load(os.path.join(base_dir, data_path, id_, 'X_test.npy'), allow_pickle=True)
    _params = np.load(os.path.join(base_dir, data_path, id_, 'params_test.npy'), allow_pickle=True)
    _cond_params = np.load(os.path.join(base_dir, data_path, id_, 'cond_params_test.npy'), allow_pickle=True)
    _params_names = np.load(os.path.join(base_dir, data_path, id_, 'params_names.npy'), allow_pickle=True)
    _cond_params_names = np.load(os.path.join(base_dir, data_path, id_, 'cond_params_names.npy'), allow_pickle=True)
    _ids = np.load(os.path.join(base_dir, data_path, id_, 'ids_test.npy'), allow_pickle=True)
    _axis_labels = np.load(os.path.join(base_dir, data_path, id_, 'axis_labels.npy'), allow_pickle=True)
    _z = np.load(os.path.join(base_dir, data_path, id_, 'z_test.npy'), allow_pickle=True)
    _decoded = np.load(os.path.join(base_dir, data_path, id_, 'decoded_test.npy'), allow_pickle=True)
    
    dict_ = {'X': _X,
             'params': _params,
             'cond_params': _cond_params,
             'params_names': _params_names,
             'cond_params_names': _cond_params_names,
             'ids': _ids,
             'axis_labels': _axis_labels,
             'z': _z,
             'decoded': _decoded,
            }
    
    if include_training:
        _X_train = np.load(os.path.join(data_path, id_, 'X_train.npy'), allow_pickle=True)
        _params_train = np.load(os.path.join(data_path, id_, 'params_train.npy'), allow_pickle=True)
        _cond_params_train = np.load(os.path.join(data_path, id_, 'cond_params_train.npy'), allow_pickle=True)
        _ids_train = np.load(os.path.join(data_path, id_, 'ids_train.npy'), allow_pickle=True)
        _z_train = np.load(os.path.join(data_path, id_, 'z_train.npy'), allow_pickle=True)
        _decoded_train = np.load(os.path.join(data_path, id_, 'decoded_train.npy'), allow_pickle=True)
        dict_['X_train'] = _X_train
        dict_['params_train'] = _params_train
        dict_['cond_params_train'] = _cond_params_train
        dict_['ids_train'] = _ids_train
        dict_['z_train'] = _z_train
        dict_['decoded_train'] = _decoded_train
        
    return dict_

def load_models(model_id, model_path='results/models', verbose=0):
    '''Load autoencoder and discriminator model given an id
    
    Parameters
    ----------
    model_id : str
        Model identifier
    model_path : str, default 'results/models'
        Path of the folder where the model is saved
    verbose : int, default 0
        Verbose
    '''
    
    verbose and print('Loading models from {:}... '.format(os.path.normpath(os.path.join(model_path, model_id))))
    
    # Autoencoder
    _ae_path = glob.glob(os.path.join(model_path, model_id, 'autoencoder*'))[0]
    _autoencoder = tf.keras.models.load_model(_ae_path, compile=False)
    verbose and print("Model '{:}' loaded".format(os.path.basename(_ae_path)))
    
    # Discriminators
    _discriminator_dict = dict()
    _disc_paths = glob.glob(os.path.join(model_path, model_id,'*discriminator*'))
        
    for _disc_path in _disc_paths:
        _model_name = os.path.basename(_disc_path)
        _discriminator_dict[_model_name.replace('.keras','')] = tf.keras.models.load_model(_disc_path, compile=False)
        verbose and print("Model '{:}' loaded".format(_model_name))
    
    return _autoencoder, _discriminator_dict